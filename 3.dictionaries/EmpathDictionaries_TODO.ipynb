{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a55155",
   "metadata": {},
   "source": [
    "[Empath](https://github.com/Ejhfast/empath-client) is a set of dictionaries spanning 194 different topics (e.g., \"car\", \"leisure\", \"tool\", real_estate\", etc.), originally described in Fast et al. (2016), \"[Empath: Understanding Topic Signals in Large-Scale Text](https://hci.stanford.edu/publications/2016/ethan/empath-chi-2016.pdf)\".  In this work, we'll explore using empath to characterize texts and also use it as a jumping off point to think about **validity**. \n",
    "\n",
    "The Empath *category* \"help\", for example, is a dictionary that contains the following *dictionary terms*:\n",
    "\n",
    "help = {help, chore, responsible, help, grateful, maid, housekeeping, helpful, stabilize, servant, benefit, financial, aide, supportive, assistance, favor, tend, favor, encourage, wheelchair, nurse, patient, honor, protection, oversee, guide, hospitality, duty, advisor, carry, trust, obligation, rely, support, escort, friend, treat, offer, serve, cooperate, encouragement, promote, volunteer, counsel, kindly, crutch, aid, nursing, helper, request, rescue, provide, protect, generously, housework, advise, temporary, assist, entrust, prepare\n",
    "}\n",
    "\n",
    "When applied to text, we can count which *tokens* have lemmas that are *dictionary terms*, indicating that it is indicative of that corresponding *category*.  In the following text, the tokens that have lemmas corresponding to \"help\" dictionary terms have been highlighted:  \n",
    "\n",
    "(1) \"The doctor prescribed a ***wheelchair*** rather than ***crutches*** to help heal the broken leg of the ***patient***.  The hospital bill, however, was a significant ***financial*** burden to the ***patient***.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fd355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ec998",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner,parser'])\n",
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ea82d",
   "metadata": {},
   "source": [
    "First, let's read in [the Empath dictionaries](https://github.com/Ejhfast/empath-client/blob/master/empath/data/categories.tsv) and create two mappings: one mapping categories to the dictionary terms within it, and one mapping dictionary terms to the categories they belong to (words can belong to multiple categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dictionaries(filename):\n",
    "    category_to_lemmas={}\n",
    "    lemma_to_categories={}\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            category=cols[0]\n",
    "            category_to_lemmas[category]=set(cols)\n",
    "            for lemma in cols:\n",
    "                if lemma not in lemma_to_categories:\n",
    "                    lemma_to_categories[lemma]={}\n",
    "                lemma_to_categories[lemma][category]=1\n",
    "    return lemma_to_categories, category_to_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_to_categories, category_to_lemmas=read_dictionaries(\"../data/empath_categories.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559b48b",
   "metadata": {},
   "source": [
    "Now let's use it to count up the Empath categories present in an input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_empath_categories(text, lemma_to_categories):\n",
    "    category_counts=Counter()\n",
    "    tokens=nlp(text.lower())\n",
    "    for word in tokens:\n",
    "        lemma=word.lemma_\n",
    "        if lemma in lemma_to_categories:\n",
    "            for cat in lemma_to_categories[lemma]:\n",
    "                category_counts[cat]+=1\n",
    "    \n",
    "    for k,v in category_counts.most_common():\n",
    "        print(v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2825a3",
   "metadata": {},
   "source": [
    "We'll run it on the following text from [CNN](https://www.cnn.com/2021/08/31/middleeast/syria-cyprus-oil-spill-intl/index.html).\n",
    "\n",
    "\"An oil spill that originated from Syria's largest refinery is growing and spreading across the Mediterranean Sea, and could reach the island of Cyprus by Wednesday, Cypriot authorities have said.\n",
    "\n",
    "Syrian officials said last week that a tank filled with 15,000 tons of fuel had been leaking since August 23 at a thermal power plant on the Syrian coastal city of Baniyas. They said they had been able to bring it under control.\n",
    "Satellite imagery analysis by Orbital EOS now indicates that the oil spill was larger than originally thought, covering around 800 square kilometres (309 square miles) -- an area around the same size as New York City. The company told CNN Tuesday evening that the oil slick was around 7 kilometers (4 miles) from the Cypriot coast.\n",
    "The Cypriot Department of Fisheries and Marine research said that, based on a simulation of the oil spill's movements and meteorological data, the slick could reach the Apostlos Andreas Cape \"in the next 24 hours.\" The department posted the statement at around 11 a.m. local time (4 a.m. ET) on Tuesday.\n",
    "It also said it would be willing to assist in tackling the spill.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18490f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"An oil spill that originated from Syria's largest refinery is growing and spreading across the Mediterranean Sea, and could reach the island of Cyprus by Wednesday, Cypriot authorities have said.\n",
    "\n",
    "Syrian officials said last week that a tank filled with 15,000 tons of fuel had been leaking since August 23 at a thermal power plant on the Syrian coastal city of Baniyas. They said they had been able to bring it under control.\n",
    "Satellite imagery analysis by Orbital EOS now indicates that the oil spill was larger than originally thought, covering around 800 square kilometres (309 square miles) -- an area around the same size as New York City. The company told CNN Tuesday evening that the oil slick was around 7 kilometers (4 miles) from the Cypriot coast.\n",
    "The Cypriot Department of Fisheries and Marine research said that, based on a simulation of the oil spill's movements and meteorological data, the slick could reach the Apostlos Andreas Cape \"in the next 24 hours.\" The department posted the statement at around 11 a.m. local time (4 a.m. ET) on Tuesday.\n",
    "It also said it would be willing to assist in tackling the spill.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8961fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_empath_categories(text, lemma_to_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765bd82",
   "metadata": {},
   "source": [
    "Remember that dictionaries operate at the type level -- *every* instance of the word \"financial\", for instance, evokes the Empath \"help\" category, even though specific tokens of \"financial\" in context may not. Let's first identify what tokens in a text are evoking specific Empath categories, so we can examine them for their correctness.\n",
    "\n",
    "**Q1:** Write a function that identifies the *tokens* corresponding to specific *dictionary terms* for an input *category* present in a given input text. This function should highlight those specific tokens in context by wrapping them in \\*\\*\\*.  Taking the category \"help\" and the input text given in (1) above, your output should look like the following:\n",
    "\n",
    "The doctor prescribed a \\*\\*\\*wheelchair\\*\\*\\* rather than \\*\\*\\*crutches\\*\\*\\* to help heal the broken leg of the \\*\\*\\*patient\\*\\*\\*.  The hospital bill, however, was a significant \\*\\*\\*financial\\*\\*\\* burden to the \\*\\*\\*patient\\*\\*\\*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cab4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_empath_tokens_in_context(text, category_to_lemmas, category):\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca188da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_empath_tokens_in_context(text, category_to_lemmas, \"liquid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15f5fb",
   "metadata": {},
   "source": [
    "**Q2.** Use the function you just wrote to find all tokens identified by the \"liquid,\" \"fire,\" \"beach\" and \"ocean\" categories and use them to fill out the table below.  Judge whether or not each token in context actually belongs to that category. Include a rationale if you think the decision would be contestable.\n",
    "\n",
    "|Category|Token in Context|Label|Rationale (if needed)\n",
    "|---|---|---|---|\n",
    "|liquid|the mediterranean ***sea***, and could|Correct|N/A|\n",
    "\n",
    "You have a total of 20 rows (8 liquid, 4 fire, 4 beach, and 4 ocean, as identified above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000359ef",
   "metadata": {},
   "source": [
    "**Q3.** Using that table, calculate the precision of the \"liquid,\" \"fire,\" \"beach\" and \"ocean\" categories for this passage using the following equation:\n",
    "\n",
    "$$\n",
    "\\textrm{Precision(liquid)} = {{\\textrm{# of \"liquid\" tokens identified by Empath that you marked as correct}} \\over {\\textrm{# of \"liquid\" tokens identified by Empath}}}\n",
    "$$\n",
    "\n",
    "You should report 4 numbers (one measure of precision for each of the 4 categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad9eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
