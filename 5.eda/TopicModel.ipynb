{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll explore topic modeling to discover broad themes in a collection of movie summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbamman/opt/anaconda3/envs/anlp/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dbamman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import operator\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(filename):\n",
    "    stopwords={}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            stopwords[line.rstrip()]=1\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're running topic modeling on texts with lots of names, we'll add the Jockers list of stopwords (which includes character names) to our stoplist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {k:1 for k in stopwords.words('english')}\n",
    "stop_words.update(read_stopwords(\"../data/jockers.stopwords\"))\n",
    "stop_words[\"'s\"]=1\n",
    "stop_words=list(stop_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(word, stopwords):\n",
    "    \n",
    "    \"\"\" Function to exclude words from a text \"\"\"\n",
    "    \n",
    "    # no stopwords\n",
    "    if word in stopwords:\n",
    "        return False\n",
    "    \n",
    "    # has to contain at least one letter\n",
    "    if re.search(\"[A-Za-z]\", word) is not None:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docs(plotFile, metadataFile, stopwords):\n",
    "    \n",
    "    names={}\n",
    "    box={}\n",
    "    \n",
    "    with open(metadataFile, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            idd=cols[0]\n",
    "            name=cols[2]\n",
    "            boxoffice=cols[4]\n",
    "            if len(boxoffice) != 0:\n",
    "                box[idd]=int(boxoffice)\n",
    "                names[idd]=name\n",
    "    \n",
    "    n=5000\n",
    "    target_movies={}\n",
    "\n",
    "\n",
    "    sorted_box = sorted(box.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_box[:n]:\n",
    "        target_movies[k]=names[k]\n",
    "    \n",
    "    docs=[]\n",
    "    names=[]\n",
    "   \n",
    "    with open(plotFile, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            idd=cols[0]\n",
    "            text=cols[1]\n",
    "            \n",
    "            if idd in target_movies:\n",
    "                tokens=nltk.word_tokenize(text.lower())\n",
    "                tokens=[x for x in tokens if filter(x, stopwords)]\n",
    "                docs.append(tokens)\n",
    "                name=target_movies[idd]\n",
    "                names.append(name)\n",
    "    return docs, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in summaries of the 5,000 movies with the highest box office revenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataFile=\"../data/movie.metadata.tsv\"\n",
    "plotFile=\"../data/plot_summaries.txt\"\n",
    "data, doc_names=read_docs(plotFile, metadataFile, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the movie summaries into a bag-of-words representation using gensim's [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab from data; restrict vocab to only the top 10K terms that show up in at least 5 documents \n",
    "# and no more than 50% of all documents\n",
    "\n",
    "dictionary = corpora.Dictionary(data)\n",
    "dictionary.filter_extremes(no_below=5, no_above=.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dataset with numeric ids words in vocab (and exclude all other words)\n",
    "corpus = [dictionary.doc2bow(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a topic model on this data using gensim's built-in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics, \n",
    "                                           passes=10,\n",
    "                                           alpha='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sense of what the topics are by printing the top 10 words with highest $P(word \\mid topic)$ for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\thouse find finds body room begins killed goes tries inside\n",
      "topic 1:\ttown prison case sheriff judge smith trial murder police court\n",
      "topic 2:\tschool tells father time life day mother film friends friend\n",
      "topic 3:\tearth alien planet ship machine space aliens humans crew human\n",
      "topic 4:\tstone kid dj vega kramer pop smoke play party stab\n",
      "topic 5:\tmrs. boone camp kids cat hayes whale butch tooth stark\n",
      "topic 6:\tteam game coach football west players player play win national\n",
      "topic 7:\tdr. evil de satan god soul death body father priest\n",
      "topic 8:\tfather family mother away find help named tells children return\n",
      "topic 9:\twhite doc snow burke jones shark penguins oz pink penguin\n",
      "topic 10:\tcar police tells money house goes finds find apartment night\n",
      "topic 11:\tagent bomb bond fbi plane agents kill escape killed president\n",
      "topic 12:\tfight battle army kill robot soldiers city attack men orders\n",
      "topic 13:\tdracula vampire toys count silver werewolf barnes bug toy ferguson\n",
      "topic 14:\twar army soldiers men american general japanese camp miller killed\n",
      "topic 15:\tfilm life woman story daughter mother husband death wife father\n",
      "topic 16:\tthompson lucky fairies ace slim edwards blanket bowl montgomery super\n",
      "topic 17:\tpolice gang kill drug killed shoots kills death gun shot\n",
      "topic 18:\ttrain ash brown sullivan stevens pok√©mon company pikachu money sawyer\n",
      "topic 19:\tship island captain crew boat group find city escape water\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model.show_topic(i, topn=10)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of understanding topics is to print out the documents that have the highest topic representation -- i.e., for a given topic $k$, the documents with highest $P(topic=k | document)$.  How much do the documents listed here align with your understanding of the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house find finds body room begins killed goes tries inside\n",
      "\n",
      "0\t0.970\tThe Final Destination\n",
      "0\t0.940\tA Nightmare on Elm Street 2: Freddy's Revenge\n",
      "0\t0.906\tFriday the 13th\n",
      "0\t0.878\tDeadly Friend\n",
      "0\t0.870\tA Nightmare on Elm Street\n",
      "\n",
      "town prison case sheriff judge smith trial murder police court\n",
      "\n",
      "1\t0.940\tNeedful Things\n",
      "1\t0.897\tWithout a Clue\n",
      "1\t0.874\tMurder in the First\n",
      "1\t0.804\tAnother Public Enemy\n",
      "1\t0.733\tThe Shawshank Redemption\n",
      "\n",
      "school tells father time life day mother film friends friend\n",
      "\n",
      "2\t0.997\tProm\n",
      "2\t0.995\tShopgirl\n",
      "2\t0.995\tNational Lampoon's Van Wilder\n",
      "2\t0.995\tParenthood\n",
      "2\t0.993\tFriends with Kids\n",
      "\n",
      "earth alien planet ship machine space aliens humans crew human\n",
      "\n",
      "3\t0.777\tStar Trek Nemesis\n",
      "3\t0.614\tStar Trek\n",
      "3\t0.613\tStar Trek: The Motion Picture\n",
      "3\t0.601\tSupernova\n",
      "3\t0.594\tGalaxy Quest\n",
      "\n",
      "stone kid dj vega kramer pop smoke play party stab\n",
      "\n",
      "4\t0.424\tHouse Party\n",
      "4\t0.226\tBiker Boyz\n",
      "4\t0.214\tHouse Party 2\n",
      "4\t0.178\tHouse Party 3\n",
      "4\t0.158\tStomp the Yard\n",
      "\n",
      "mrs. boone camp kids cat hayes whale butch tooth stark\n",
      "\n",
      "5\t0.364\tIron Man 2\n",
      "5\t0.343\tCamp Nowhere\n",
      "5\t0.326\tIron Man\n",
      "5\t0.271\tIndian Summer\n",
      "5\t0.270\tOld Dogs\n",
      "\n",
      "team game coach football west players player play win national\n",
      "\n",
      "6\t0.645\tMiracle\n",
      "6\t0.584\tD2: The Mighty Ducks\n",
      "6\t0.570\tStrange Wilderness\n",
      "6\t0.541\tThe Comebacks\n",
      "6\t0.515\tSneakers\n",
      "\n",
      "dr. evil de satan god soul death body father priest\n",
      "\n",
      "7\t0.957\tLost Souls\n",
      "7\t0.822\tHighlander: The Final Dimension\n",
      "7\t0.610\tThe Mummy\n",
      "7\t0.577\tThe Order\n",
      "7\t0.541\tVan Helsing\n",
      "\n",
      "father family mother away find help named tells children return\n",
      "\n",
      "8\t0.966\tBenji\n",
      "8\t0.945\tShrek 2\n",
      "8\t0.940\tCrying Fist\n",
      "8\t0.934\tThe Next Best Thing\n",
      "8\t0.923\tTuck Everlasting\n",
      "\n",
      "white doc snow burke jones shark penguins oz pink penguin\n",
      "\n",
      "9\t0.452\tSwearing Allegiance\n",
      "9\t0.439\tDazed and Confused\n",
      "9\t0.355\tReservoir Dogs\n",
      "9\t0.334\tCool World\n",
      "9\t0.329\tBack to the Future\n",
      "\n",
      "car police tells money house goes finds find apartment night\n",
      "\n",
      "10\t0.995\tDrive\n",
      "10\t0.989\tA Perfect Murder\n",
      "10\t0.952\tNext Day Air\n",
      "10\t0.865\tSet It Off\n",
      "10\t0.851\tVoice of a Murderer\n",
      "\n",
      "agent bomb bond fbi plane agents kill escape killed president\n",
      "\n",
      "11\t0.979\tDie Hard 2\n",
      "11\t0.977\tSnakes on a Plane\n",
      "11\t0.968\tExecutive Decision\n",
      "11\t0.954\tThe Peacemaker\n",
      "11\t0.954\tPassenger 57\n",
      "\n",
      "fight battle army kill robot soldiers city attack men orders\n",
      "\n",
      "12\t0.814\tD-War\n",
      "12\t0.813\tThe 13th Warrior\n",
      "12\t0.773\tThe Last Samurai\n",
      "12\t0.743\tThe Last Dragon\n",
      "12\t0.736\tFinal Fantasy: The Spirits Within\n",
      "\n",
      "dracula vampire toys count silver werewolf barnes bug toy ferguson\n",
      "\n",
      "13\t0.897\tEyyvah Eyvah 2\n",
      "13\t0.464\tDracula 2000\n",
      "13\t0.430\tValley of the Wolves: Palestine\n",
      "13\t0.395\tDracula: Dead and Loving It\n",
      "13\t0.384\tFat Pizza: The Movie\n",
      "\n",
      "war army soldiers men american general japanese camp miller killed\n",
      "\n",
      "14\t0.957\tThe Green Berets\n",
      "14\t0.879\tWe Were Soldiers\n",
      "14\t0.870\tThe Steel Helmet\n",
      "14\t0.833\tThe Thin Red Line\n",
      "14\t0.826\tEnemy at the Gates\n",
      "\n",
      "film life woman story daughter mother husband death wife father\n",
      "\n",
      "15\t0.979\tThe Last Station\n",
      "15\t0.962\tImmortal Beloved\n",
      "15\t0.894\tOn Golden Pond\n",
      "15\t0.843\tArsene Lupin\n",
      "15\t0.812\tFrida\n",
      "\n",
      "thompson lucky fairies ace slim edwards blanket bowl montgomery super\n",
      "\n",
      "16\t0.154\tAce Ventura: When Nature Calls\n",
      "16\t0.139\tHome on the Range\n",
      "16\t0.131\tStakeout\n",
      "16\t0.121\tAce Ventura: Pet Detective\n",
      "16\t0.112\tWhere the Buffalo Roam\n",
      "\n",
      "police gang kill drug killed shoots kills death gun shot\n",
      "\n",
      "17\t0.896\tExit Wounds\n",
      "17\t0.884\tDeuces Wild\n",
      "17\t0.855\tAn Eye for an Eye\n",
      "17\t0.822\tDaisy\n",
      "17\t0.804\tOpen City\n",
      "\n",
      "train ash brown sullivan stevens pok√©mon company pikachu money sawyer\n",
      "\n",
      "18\t0.496\tSource Code\n",
      "18\t0.464\tRollover\n",
      "18\t0.362\tJust Cause\n",
      "18\t0.331\tPok√©mon: Spell Of The Unown\n",
      "18\t0.318\tPok√©mon 4Ever\n",
      "\n",
      "ship island captain crew boat group find city escape water\n",
      "\n",
      "19\t0.931\tIce Age: Continental Drift\n",
      "19\t0.873\tMaster and Commander: The Far Side of the World\n",
      "19\t0.827\tDinosaur\n",
      "19\t0.800\tNight at the Museum: Battle of the Smithsonian\n",
      "19\t0.788\tPirates of the Caribbean: On Stranger Tides\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_model=lda_model \n",
    "\n",
    "topic_docs=[]\n",
    "for i in range(num_topics):\n",
    "    topic_docs.append({})\n",
    "for doc_id in range(len(corpus)):\n",
    "    doc_topics=topic_model.get_document_topics(corpus[doc_id])\n",
    "    for topic_num, topic_prob in doc_topics:\n",
    "        topic_docs[topic_num][doc_id]=topic_prob\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print(\"%s\\n\" % ' '.join([term for term, freq in topic_model.show_topic(i, topn=10)]))\n",
    "    sorted_x = sorted(topic_docs[i].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_x[:5]:\n",
    "        print(\"%s\\t%.3f\\t%s\" % (i,v,doc_names[k]))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
