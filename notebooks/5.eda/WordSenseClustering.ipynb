{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc226e1",
   "metadata": {},
   "source": [
    "[Lucy and Bamman 2021](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00383/101877/Characterizing-English-Variation-across-Social) uses KMeans clustering over BERT representations to learn word senses in order to characterize their distinctive use within online communities.  In this notebook, we'll explore inferring distinct senses using clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778bb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ebd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_for_token(string, term):\n",
    "    \n",
    "    # tokenize\n",
    "    inputs = tokenizer(string, return_tensors=\"pt\")\n",
    "    \n",
    "    # convert input ids to words\n",
    "    tokens=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    \n",
    "    # find the first location of the query term among those tokens (so we know which BERT rep to use)\n",
    "    term_idx=tokens.index(term)\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # return the BERT rep for that token index\n",
    "    # The output is a pytorch tensor object, but let's convert it to a numpy object to work with numpy functions\n",
    "    \n",
    "    return outputs.last_hidden_state[0][term_idx].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6125829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data.append(line.rstrip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6507986",
   "metadata": {},
   "source": [
    "First, let's examine uses of the word \"cabinet\" from several contemporary novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05de50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_data(\"../data/cabinet.txt\")\n",
    "reps=[]\n",
    "for sentence in data:\n",
    "    reps.append(get_bert_for_token(sentence, \"cabinet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f91ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e76f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.argsort(kmeans.labels_):\n",
    "    print(\"%s\\t%s\" % (kmeans.labels_[idx], data[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe2864",
   "metadata": {},
   "source": [
    "Now let's examine a word that has slightly more polysemy: *right*.  Explore clustering with different number of clusters; how many clusters do you need to settle on what you would consider to be the right number of distinct senses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_data(\"../data/right200.txt\")\n",
    "reps=[]\n",
    "for sentence in data:\n",
    "    reps.append(get_bert_for_token(sentence, \"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1dbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_class=5\n",
    "cluster_counts=Counter()\n",
    "last_lab=None\n",
    "for idx in np.argsort(kmeans.labels_):\n",
    "    clusterID=kmeans.labels_[idx]\n",
    "    if cluster_counts[clusterID] < max_per_class:\n",
    "        cluster_counts[clusterID]+=1\n",
    "        if clusterID != last_lab and last_lab is not None:\n",
    "            print()\n",
    "        last_lab=clusterID\n",
    "        print(\"%s\\t%s\" % (clusterID, data[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b317daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
