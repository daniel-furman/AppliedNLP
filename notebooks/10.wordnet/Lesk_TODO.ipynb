{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import operator"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/anaconda3/envs/anlp/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "glove_file=\"../data/glove.6B.100d.100K.txt\"\n",
    "original_file=\"../data/glove.6B.100d.100K.w2v.txt\"\n",
    "n, dimension = glove2word2vec(glove_file, original_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/xn/nc0wg5m94rs8md2f73q98w5r0000gn/T/ipykernel_9938/3320898960.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  n, dimension = glove2word2vec(glove_file, original_file)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "wv = KeyedVectors.load_word2vec_format(original_file, binary=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q1: Implement the Lesk algorithm using word vectors \\([Basile et al. 2014](https://www.aclweb.org/anthology/C/C14/C14-1151.pdf)\\), where we measure the similarity between a gloss g = $\\{ g_1, \\ldots, g_G \\}$ and context c = $\\{ c_1, \\ldots, c_C \\}$ as the cosine similarity between the sum of distributed representations:\n",
    "\n",
    "$$\n",
    "\\cos \\left(\\sum_{i=1}^G g_i, \\sum_{i=1}^C c_i  \\right)\n",
    "$$\n",
    "\n",
    "* The gloss for a synset can be found in `synset.definition()`; be sure to tokenize it appropriately.  \n",
    "* You can find the cosine *distance* (not similarity) between two vectors using the `scipy.spatial.distance.cosine(vector_one, vector_two)` function.\n",
    "* `wn.synsets(word, pos=part_of_speech)` gets you a list of the synsets for a word with a specific part of speech (e.g., \"n\" for noun)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "def lesk(word, sentence, part_of_speech):\n",
    "    # look up\n",
    "    synsets_list = []\n",
    "    synsets_ = []\n",
    "    synsets=wn.synsets(word, pos=part_of_speech)\n",
    "    for synset in synsets:\n",
    "        string = str(synset.definition())\n",
    "        synsets_list.append(nltk.tokenize.word_tokenize(string.lower()))\n",
    "        synsets_.append(string)\n",
    "        #print (synset, synset.definition())\n",
    "    \n",
    "    # build context\n",
    "    context = nltk.tokenize.word_tokenize(sentence.lower())\n",
    "    context = context[0:len(context)-1] #words to left of bank\n",
    "\n",
    "    # building semantic vectors \n",
    "    # synsets list\n",
    "    synsets_embeddings = []\n",
    "    for i in range(0, len(synsets_list)):\n",
    "        intermediate_synsets_list = []\n",
    "        for j in range(0, len(synsets_list[i])):\n",
    "            intermediate_synsets_list.append(wv.get_vector(synsets_list[i][j]))\n",
    "        synsets_embeddings.append(sum(intermediate_synsets_list))\n",
    "        # context embeddings [0] is summed embedding of [0] definiton in synset\n",
    "    \n",
    "    context_embeddings = []\n",
    "    for i in range(0, len(context)):\n",
    "        context_embeddings.append(wv.get_vector(context[i]))\n",
    "    context_embedding = sum(context_embeddings)\n",
    "\n",
    "    # cos similarities\n",
    "    cosine_similarities = []\n",
    "    for i in range(0, len(synsets_embeddings)):\n",
    "        cosine_similarities.append(1-cosine(context_embedding, synsets_embeddings[i]))\n",
    "\n",
    "    # select highest cos score\n",
    "    max_index = cosine_similarities.index(max(cosine_similarities))\n",
    "    return synsets_[max_index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the following two cells to check whether your implementation distinguishes between these two senses of \"bank\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "lesk(\"bank\", \"I deposited my money into my savings account at the bank\", \"n\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'a financial institution that accepts deposits and channels the money into lending activities'"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "lesk(\"bank\", \"I ran along the river bank\", \"n\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sloping land (especially the slope beside a body of water)'"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# my implementation correctly distinguishes between the two types of \"bank\"."
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('anlp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "15eb0101752dc194b0d948fd2539d8e9e05a4bb72c0b2bdbdffc1aa4169aa5ff"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}